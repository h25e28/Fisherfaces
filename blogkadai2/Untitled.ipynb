{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽出方法：AKAZE\n",
      "TARGET: shiraishi.jpg\n",
      "akimoto.png 214.3125\n",
      "akimoto2.jpg 158.8125\n",
      "akimoto3.jpg 143.3125\n",
      "akimoto4.jpg 124.9375\n",
      "akimoto5.jpg 138.1875\n",
      "ikuta.jpg 100.875\n",
      "karin.png 124.125\n",
      "manatsu.jpg 131.0\n",
      "manatsu2.png 127.125\n",
      "manatsu_eyes.jpg 163.25\n",
      "nishino.png 163.9375\n",
      "nyanchu.png 117.3125\n",
      "nyanchu_eyes.png 116.8125\n",
      "sonano.jpg 138.75\n",
      "two1.jpg 151.25\n",
      "two2.jpg 132.625\n",
      "twoshot_akimoto.jpg 138.375\n",
      "twoshot_unagi.jpg 131.875\n",
      "unagi.png 122.3125\n",
      "unagi2.jpg 136.625\n",
      "unagi3.jpg 148.4375\n",
      "unagi4.jpg 179.4375\n"
     ]
    }
   ],
   "source": [
    "target_file = 'shiraishi.jpg'\n",
    "#img_dir = os.path.abspath(os.path.dirname(\"__file__\")) + '/images/'\n",
    "img_size = (200, 200)\n",
    "\n",
    "\n",
    "target_img_path = \"./images/\" + target_file\n",
    "target_img = cv2.imread(target_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "target_img = cv2.resize(target_img, img_size)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "#detector = cv2.ORB_create()\n",
    "detector = cv2.AKAZE_create()\n",
    "(target_kp, target_des) = detector.detectAndCompute(target_img, None)\n",
    "\n",
    "print(\"抽出方法：AKAZE\")\n",
    "print('TARGET: %s' % (target_file))\n",
    "\n",
    "files = os.listdir(\"./images/\")\n",
    "for file in files:\n",
    "    if file == '.DS_Store' or file == target_file:\n",
    "        continue\n",
    "\n",
    "    comparing_img_path = \"./images/\" + file\n",
    "    try:\n",
    "        comparing_img = cv2.imread(comparing_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        comparing_img = cv2.resize(comparing_img, img_size)\n",
    "        (comparing_kp, comparing_des) = detector.detectAndCompute(comparing_img, None)\n",
    "        matches = bf.match(target_des, comparing_des)\n",
    "        dist = [m.distance for m in matches]\n",
    "        ret = sum(dist) / len(dist)\n",
    "    except cv2.error:\n",
    "        ret = 100000\n",
    "\n",
    "    print(file, ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Image: subject01.akimoto.jpg, Predicted Label: 1, Confidence: 21.786044627006834\n",
      "Test Image: subject02.asuka.jpg, Predicted Label: 2, Confidence: 51.351808634017296\n",
      "Test Image: subject03.hori.jpg, Predicted Label: 3, Confidence: 44.75424378786359\n",
      "Test Image: subject04.ikuta.jpg, Predicted Label: 4, Confidence: 45.70965779143789\n",
      "Test Image: subject05shiraishi.jpg, Predicted Label: 5, Confidence: 49.08969544979982\n",
      "Test Image: subject06nishino.jpg, Predicted Label: 6, Confidence: 43.72499865726888\n",
      "Test Image: subject07.unagi.png, Predicted Label: 1, Confidence: 63.37511081588498\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "#トレーニング画像\n",
    "train_path = './train_images'\n",
    "\n",
    "#テスト画像\n",
    "test_path = './test_images'\n",
    "\n",
    "#Haar-like特徴分類器\n",
    "cascadePath = \"/Users/daichi/Downloads/opencv-3.4.1/opencv-3.4.1/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath)\n",
    "\n",
    "#FisherFace\n",
    "#recognizer = cv2.face_FisherFaceRecognizer.create()\n",
    "recognizer = cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "#pathしたフォルダ内の画像を習得\n",
    "def get_images_and_labels(path):\n",
    "    #画像を格納する配列\n",
    "    images = []\n",
    "    #ラベルを格納する配列\n",
    "    labels = []\n",
    "    #ファイル名を格納する配列\n",
    "    files = []\n",
    "    for f in os.listdir(path):\n",
    "        #画像のパス\n",
    "        image_path = os.path.join(path, f)\n",
    "        #グレースケールで読み込み\n",
    "        image_pil = Image.open(image_path).convert('L')\n",
    "        #Numpyの配列に格納\n",
    "        image = np.array(image_pil, 'uint8')\n",
    "        #Haar-like特徴分類器で顔を検知\n",
    "        faces = faceCascade.detectMultiScale(image)\n",
    "        #検出した画像の処理\n",
    "        for(x, y, w, h) in faces:\n",
    "            #200×200にリサイズ\n",
    "            roi = cv2.resize(image[y: y + h, x: x + w], (200, 200), interpolation=cv2.INTER_LINEAR)\n",
    "            #画像を配列に格納\n",
    "            images.append(roi)\n",
    "            #ファイル名からラベルを取得\n",
    "            labels.append(int(f[7:9]))\n",
    "            #ファイル名を配列に格納\n",
    "            files.append(f)\n",
    "    \n",
    "    return images, labels, files\n",
    "\n",
    "#トレーニング画像を取得\n",
    "images, labels, files = get_images_and_labels(train_path)\n",
    "\n",
    "#トレーニング実施\n",
    "recognizer.train(images, np.array(labels))\n",
    "\n",
    "#テスト画像を取得\n",
    "test_images, test_labels, test_files = get_images_and_labels(test_path)\n",
    "\n",
    "i=0\n",
    "while i < len(test_labels):\n",
    "    #テスト画像に対して予測実施\n",
    "    label, confidence = recognizer.predict(test_images[i])\n",
    "    #予測結果をコンソール出力\n",
    "    print(\"Test Image: {}, Predicted Label: {}, Confidence: {}\".format(test_files[i], label, confidence))\n",
    "    #テスト画像表示\n",
    "    cv2.imshow(\"test image\", test_images[i])\n",
    "    cv2.waitKey(300)\n",
    "    i += 1\n",
    "\n",
    "#終了処理\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
